{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2acfc6-faa0-4b2b-a487-96a7e50b2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "#===============================================================================\n",
    "#\n",
    "#           FILE: unigramMNB_3_ntb.py\n",
    "#         AUTHOR: Bianca Ciobanica\n",
    "#\t       EMAIL: bianca.ciobanica@student.uclouvain.be\n",
    "#\n",
    "#           BUGS: \n",
    "#        VERSION: 3.10.6\n",
    "#        CREATED: 25-10-2023 \n",
    "#\n",
    "#===============================================================================\n",
    "#    DESCRIPTION: sources used for this code : \n",
    "#               https://medium.com/@johnm.kovachi/implementing-a-multinomial-naive-bayes-classifier-from-scratch-with-python-e70de6a3b92e\n",
    "#               https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\n",
    "#               https://datasciencedojo.com/blog/naive-bayes-from-scratch-part-1/#\n",
    "#               http://web.stanford.edu/~jurafsky/slp3/4.pdf\n",
    "# \n",
    "#    \n",
    "#          USAGE: \n",
    "#==============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29a0238-c21e-48dd-828a-7682a234199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.lm import Vocabulary\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c33bd68-7d2a-4f39-8c3a-9bd43f5fab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "  import re\n",
    "  clean = re.compile('<.*?>')\n",
    "  return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "734d9087-c12e-47b7-8a44-6e4e2bad7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(df, threshold):\n",
    "        tokenized_corpus = [token \n",
    "                            for row in df\n",
    "                            for token in row] # flattened corpus\n",
    "\n",
    "        word_counts = Counter(tokenized_corpus)\n",
    "    \n",
    "        restricted_voc = ['<UNK>' if word_counts[word] < threshold else word for word in tokenized_corpus]\n",
    "    \n",
    "        return Counter(restricted_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ffc67e-bffc-4cf1-812d-d96a7d2d7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training corpus\n",
    "df_corpus = pd.read_csv(\"data/train.csv\")\n",
    "unk_threshold = 3\n",
    "# preprocess \n",
    "df_corpus['Body'] = df_corpus['Body'].apply(lambda x: remove_html_tags(x))\n",
    "df_corpus['Body_tokenized'] = df_corpus['Body'].apply(lambda x: WordPunctTokenizer().tokenize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f52fc2-bc7f-46d8-b9bd-c3797077d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Body', 'Y', 'Body_tokenized'], dtype='object')\n",
      "(14000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_corpus.keys())\n",
    "print(df_corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4743a8bb-9ef0-4bc1-a35f-a703ba49f2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HQ', 'LQ']\n"
     ]
    }
   ],
   "source": [
    "classes_counts = len(df_corpus['Y'])\n",
    "classes = df_corpus['Y'].unique().tolist()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e08fa63d-111a-4fbf-b33b-c0ef4e652039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(tokenized_corpus))\n",
    "#print(\"bigdoc voc size: \", bigdoc_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9db7dfac-c2b6-4804-b735-2dfc9bd32d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(class | doc) = (P(doc | class) * P(class)) / P(doc)\n",
    "# p(  x   |  y ) = (P( y  |  x   ) * P( x ) ) / P( y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14e30e78-c3a0-4fab-927a-23b228548240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    # This code is inspired by code generated with the GPT-3 model developed by OpenAI.\n",
    "    # I initally created a NB model which i would then initialize per class\n",
    "    # But then I realized i should create a model which iterates through each class as shown in SLP\n",
    "    \n",
    "    def __init__(self, docs, classes, alpha=None, voc = None):\n",
    "        self.bigdoc = docs\n",
    "        self.classes = classes\n",
    "        self.alpha = alpha\n",
    "        self.bigdoc_v = voc # is a Counter obj\n",
    "        self.bigdoc_v_size = self.bigdoc_v.total()\n",
    "        \n",
    "        self.bow = {}\n",
    "        self.logprior = {}\n",
    "        self.logll = {}\n",
    "        self.probability = {}\n",
    "       \n",
    "    def train(self):\n",
    "        if self.bigdoc_v is None or len(self.bigdoc_v) == 0:\n",
    "            raise ValueError(\"Cannot train on an empty vocabulary.\")\n",
    "        \n",
    "        total_doc_counts = len(self.bigdoc)\n",
    "        # go through each class\n",
    "        for label in self.classes:\n",
    "            print(self.alpha)\n",
    "            # get features from class\n",
    "            class_docs = self.bigdoc[self.bigdoc['Y'] == label]\n",
    "            class_counts = len(class_docs)\n",
    "            \n",
    "            # get P(c)\n",
    "            self.logprior[label] = log(class_counts / total_doc_counts)\n",
    "            \n",
    "            # generate bag of words with freq\n",
    "            self.bow[label] = self.extract_features(class_docs)\n",
    "            \n",
    "            class_bow = self.bow[label] \n",
    "            total_class_tokens = class_bow.total()\n",
    "            self.logll[label] = {}\n",
    "            self.probability[label] = {}\n",
    "            \n",
    "             # calculate log likelihood\n",
    "            for token in self.bigdoc_v: # store logll for each token in each class\n",
    "                count_w = class_bow.get(token,0.0)\n",
    "               # print(label, token, prob_word)\n",
    "                self.logll[label][token] = log((count_w + self.alpha) / (total_class_tokens + self.bigdoc_v_size * self.alpha))\n",
    "                if token in class_bow:\n",
    "                    self.probability[label][token] = class_bow[token] / total_class_tokens\n",
    "\n",
    "    def check_consistency(self):\n",
    "        probs = {}\n",
    "        for label in self.classes:\n",
    "            p = 0\n",
    "            for token in self.probability[label]:\n",
    "                p += self.probability[label][token]\n",
    "            probs[label] = p\n",
    "            \n",
    "        #print(probs)\n",
    "        \n",
    "        is_consistent = False\n",
    "        p_class1, p_class2 = probs.values()\n",
    "        if round(p_class1) == 1 and round (p_class2) == 1:\n",
    "            is_consistent = True\n",
    "        return \"Is consistent : \" + str(is_consistent)\n",
    "        \n",
    "        \n",
    "    def test_model(self, test_doc):\n",
    "        sums = {} # {\"class\" : logprior}\n",
    "        #C_NB = argmax (logprior + sum logll)\n",
    "        \n",
    "        for label in self.classes:\n",
    "            sums[label] = self.logprior[label]\n",
    "            # go through each word\n",
    "            for token in test_doc:\n",
    "                if token in self.bigdoc_v:\n",
    "                    sums[label] += self.logll[label][token]\n",
    "        \n",
    "        # get class with highest score\n",
    "        argmax = max(sums, key=sums.get)\n",
    "        return argmax\n",
    "\n",
    "    def test_accuracy(self, data=None, data_type=None):\n",
    "        if data is None or data.empty:\n",
    "            raise ValueError(\"Cannot train on an empty corpus.\")\n",
    "            \n",
    "        correct_predictions = 0;\n",
    "        total_predictions = 0;\n",
    "    \n",
    "        for index, row in data.iterrows(): # used GPT to help me find how to iter on rows in my df\n",
    "            true_label = row['Y']\n",
    "            predicted_label = self.test_model(row[data_type])\n",
    "           # print(true_label, \"< true =?= predicted >\", predicted_label)\n",
    "    \n",
    "            total_predictions += 1\n",
    "            if predicted_label == true_label:\n",
    "                correct_predictions += 1\n",
    "    \n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        return round(accuracy * 100, 3)\n",
    "            \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        s += \"total docs    = \" + str(len(self.bigdoc)) + \"\\n\"\n",
    "        s += \"labels        = \" + str(self.classes)+ \"\\n\"\n",
    "        s += \"Voc          = \" + str(self.bigdoc_v_size)+ \"\\n\"\n",
    "        s += \"Alpha        = \" + str(self.alpha)+ \"\\n\"\n",
    "        s+= \"_____________________\\n\"\n",
    "\n",
    "        for label in self.classes:\n",
    "            s += str(label) + \"\\n\"\n",
    "            s += \"Voc size    = \" + str(sum(self.bow[label][token] for token in self.bow[label])) + \"\\n\"\n",
    "            s += \"P(c)          = \" + str(self.logprior[label]) + \"\\n\"\n",
    "            s+= \"_____________________\\n\"\n",
    "        return s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c333cba-9bcd-46a7-bbef-3f5bf86b3a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramMultinomialNB(NaiveBayesClassifier):\n",
    "    def __init__(self, docs, classes, alpha = None, voc = None):\n",
    "        \n",
    "        super().__init__(docs,classes, alpha = alpha, voc = voc)\n",
    "\n",
    "    def extract_features (self, docs):\n",
    "        \"\"\"creates unigram counts per class\n",
    "        \"\"\"\n",
    "        flattened_docs = [token \n",
    "                          for row in docs['Body_tokenized']\n",
    "                          for token in row]\n",
    "        \n",
    "        return Counter(flattened_docs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2f42b98-6726-42d2-a3d4-ce352464fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize test corpus and prepocess it\n",
    "test_corpus = pd.read_csv(\"data/test.csv\")\n",
    "# preprocess \n",
    "test_corpus['Body'] = test_corpus['Body'].apply(lambda x: remove_html_tags(x))\n",
    "test_corpus['Body_tokenized'] = test_corpus['Body'].apply(lambda x: WordPunctTokenizer().tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b67d14cc-f431-4a06-9e26-4268298d907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdoc_voc = create_vocabulary(df_corpus['Body_tokenized'], unk_threshold) # restricted voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "314ace51-32bc-4372-b909-7e6ed3fc580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "Is consistent : True \n",
      "\n",
      "total docs    = 14000\n",
      "labels        = ['HQ', 'LQ']\n",
      "Voc          = 2653867\n",
      "Alpha        = 1\n",
      "_____________________\n",
      "HQ\n",
      "Voc size    = 1382815\n",
      "P(c)          = -0.6931471805599453\n",
      "_____________________\n",
      "LQ\n",
      "Voc size    = 1271052\n",
      "P(c)          = -0.6931471805599453\n",
      "_____________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create multinomial class conditional unigram model\n",
    "\n",
    "unigramMNB_model = UnigramMultinomialNB(df_corpus, classes, alpha=1, voc = bigdoc_voc) # Laplace smoothing\n",
    "unigramMNB_model.train()\n",
    "\n",
    "print(unigramMNB_model.check_consistency(), '\\n')\n",
    "\n",
    "print(unigramMNB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4fb8c34-9dc0-4646-9b69-1f3aca9f97de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37999/4000198818.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  true_label = row[index]['Y']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unigramMNB_accuracy \u001b[38;5;241m=\u001b[39m  \u001b[43munigramMNB_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_corpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBody_tokenized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy prediction for unigram MNB on test data :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, unigramMNB_accuracy )\n",
      "Cell \u001b[0;32mIn[43], line 89\u001b[0m, in \u001b[0;36mNaiveBayesClassifier.test_accuracy\u001b[0;34m(self, data, data_type)\u001b[0m\n\u001b[1;32m     86\u001b[0m total_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m;\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39miterrows(): \u001b[38;5;66;03m# used GPT to help me find how to iter on rows in my df\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     true_label \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     90\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_model(row[data_type])\n\u001b[1;32m     91\u001b[0m    \u001b[38;5;66;03m# print(true_label, \"< true =?= predicted >\", predicted_label)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "unigramMNB_accuracy =  unigramMNB_model.test_accuracy(test_corpus, data_type='Body_tokenized')\n",
    "print(\"Accuracy prediction for unigram MNB on test data :\\n\", unigramMNB_accuracy )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
