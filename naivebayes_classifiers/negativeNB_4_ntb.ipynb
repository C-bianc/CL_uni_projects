{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fca476c1-7882-4e6e-9256-0cd30216ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "#===============================================================================\n",
    "#\n",
    "#           FILE: negativeNB_4_ntb.py \n",
    "#         AUTHOR: Bianca Ciobanica\n",
    "#\t       EMAIL: bianca.ciobanica@student.uclouvain.be\n",
    "#\n",
    "#           BUGS: \n",
    "#        VERSION: 3.10.6\n",
    "#        CREATED: 25-10-2023 \n",
    "#\n",
    "#===============================================================================\n",
    "#    DESCRIPTION:\n",
    "#\n",
    "#          USAGE: \n",
    "#==============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e7b1db86-7499-44ac-ac3b-9176bddddf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm import Vocabulary\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3e9b9fc4-4098-40e3-903a-647783435724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "  import re\n",
    "  clean = re.compile('<.*?>')\n",
    "  return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "21f8114a-649b-4a31-ad71-78b00c4afad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(df):\n",
    "        tokenized_corpus = [token \n",
    "                            for row in df\n",
    "                            for token in row] # flattened corpus\n",
    "      \n",
    "        return Vocabulary(tokenized_corpus, unk_cutoff=unk_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "51489f97-55f3-410e-954c-7fd4cbeeaea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_negation(tokens):\n",
    "    \"\"\"\n",
    "        Theta(n) for applying _NOT to tokens between neg tokens and punctuation (or not)\n",
    "        the idea is to keep pointers of whether to apply the _NOT or no\n",
    "    \"\"\"\n",
    "    neg_tokens = ['no','not','never']\n",
    "    punctuation = ['.', ',', ':', '?', '!']\n",
    "\n",
    "    i = 0\n",
    "    apply_negation = False\n",
    "    \n",
    "    while i < len(tokens):\n",
    "        if tokens[i] in neg_tokens:\n",
    "            apply_negation = True\n",
    "            \n",
    "        elif tokens[i] in punctuation and apply_negation:\n",
    "            # stops adding _NOT because we reached punctuation\n",
    "            apply_negation = False\n",
    "            \n",
    "        elif apply_negation:\n",
    "            tokens[i] += '_NOT'\n",
    "        i += 1\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "79bc60e8-9a11-4551-a914-0172fd5adc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_first_ten_rows():\n",
    "    print(add_negation(['I', 'did', 'not', 'like', 'this', 'movie','.', 'But', 'I', 'still', 'watched', 'it','.']))\n",
    "    print(add_negation(['I', 'did', 'not', 'want', 'to', 'get', 'off', 'my', 'bed','not','to','sound','too','depressed', 'but', 'I', 'had', 'no', 'choice']))\n",
    "    for i in range (10):\n",
    "        row = df_corpus['Body_tokenized'][i]\n",
    "       # print(add_negation(row))\n",
    "#test_first_ten_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "29e337b4-4eef-405d-b7ae-3191a41e3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training corpus\n",
    "df_corpus = pd.read_csv(\"data/train.csv\")\n",
    "unk_threshold = 3\n",
    "\n",
    "# preprocess \n",
    "df_corpus['Body'] = df_corpus['Body'].apply(lambda x: remove_html_tags(x))\n",
    "df_corpus['Body_tokenized'] = df_corpus['Body'].apply(lambda x: WordPunctTokenizer().tokenize(x))\n",
    "\n",
    "# replace any token t \n",
    "#between a negative token (['not', 'no', 'never']) \n",
    "# and a punctuation sign (['.', ',', ':', '?', '!']) by the token t_NOT.\n",
    "\n",
    "df_corpus['Body_tokenized_Negation'] = df_corpus['Body_tokenized'].apply(lambda x: add_negation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d1f8548b-6713-4f63-bd70-a1b3716a4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_neg_voc = create_vocabulary(df_corpus['Body_tokenized_Negation'])\n",
    "#print(training_neg_voc['like_NOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "28e1782f-70ad-42fc-9ebf-c4e52317057d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Body', 'Y', 'Body_tokenized', 'Body_tokenized_Negation'], dtype='object')\n",
      "(14000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df_corpus.keys())\n",
    "print(df_corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ba932d4a-696a-4569-ba2a-11ddba4bdb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_counts = len(df_corpus['Y'])\n",
    "classes = df_corpus['Y'].unique().tolist()\n",
    "#print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8b876d4e-5186-4a8a-98c6-41471e624c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    # This code is inspired by code generated with the GPT-3 model developed by OpenAI.\n",
    "    # I initally created a NB model which i would then initialize per class\n",
    "    # But then I realized i should create a model which iterates through each class as shown in SLP\n",
    "    \n",
    "    def __init__(self, docs, classes, alpha=0, voc = None):\n",
    "        self.bigdoc = docs\n",
    "        self.classes = classes\n",
    "        self.alpha = alpha\n",
    "        self.bigdoc_v = voc\n",
    "        self.bigdoc_v_size = sum(self.bigdoc_v[token] for token in self.bigdoc_v if token != '<UNK>')\n",
    "        \n",
    "        self.bow = {}\n",
    "        self.logprior = {}\n",
    "        self.logll = {}\n",
    "        self.probability = {}\n",
    "       \n",
    "    def train(self):\n",
    "        if self.bigdoc_v is None or len(self.bigdoc_v) == 0:\n",
    "            raise ValueError(\"Cannot train on an empty vocabulary.\")\n",
    "        \n",
    "        total_doc_counts = len(self.bigdoc)\n",
    "        # go through each class\n",
    "        for label in self.classes:\n",
    "            # get features from class\n",
    "            class_docs = self.bigdoc[self.bigdoc['Y'] == label]\n",
    "            class_counts = len(class_docs)\n",
    "            \n",
    "            # get P(c)\n",
    "            self.logprior[label] = log(class_counts / total_doc_counts)\n",
    "            \n",
    "            # generate bag of words\n",
    "            self.bow[label] = self.extract_features(class_docs)\n",
    "            logll = 0\n",
    "            \n",
    "            # calculate log likelihood\n",
    "            class_bow = self.bow[label]\n",
    "            total_class_tokens = sum(class_bow[token] for token in class_bow)\n",
    "            self.logll[label] = {}\n",
    "            self.probability[label] = {}\n",
    "            \n",
    "            for token in self.bigdoc_v:\n",
    "                prob_word = class_bow.get(token,0)\n",
    "                self.logll[label][token] = log((prob_word + self.alpha) / (total_class_tokens + self.bigdoc_v_size * self.alpha))\n",
    "                if token in class_bow:\n",
    "                    self.probability[label][token] = class_bow[token] / total_class_tokens\n",
    "\n",
    "\n",
    "    def check_consistency(self):\n",
    "        probs = {}\n",
    "        for label in self.classes:\n",
    "            p = 0\n",
    "            for token in self.probability[label]:\n",
    "                p += self.probability[label][token]\n",
    "            probs[label] = p\n",
    "            \n",
    "        #print(probs)\n",
    "        \n",
    "        is_consistent = False\n",
    "        p_class1, p_class2 = probs.values()\n",
    "        if round(p_class1) == 1 and round (p_class2) == 1:\n",
    "            is_consistent = True\n",
    "        return \"Is consistent : \" + str(is_consistent)\n",
    "        \n",
    "    def test_model(self, test_doc):\n",
    "        sums = {} # {\"class\" : logprior}\n",
    "        #C_NB = argmax (logprior + sum logll)\n",
    "        \n",
    "        for label in self.classes:\n",
    "            sums[label] = self.logprior[label]\n",
    "            # go through each word\n",
    "            for token in test_doc:\n",
    "                if token not in self.bigdoc_v:\n",
    "                    continue\n",
    "                sums[label] = sums[label] + self.logll[label][token]\n",
    "        \n",
    "        # get class with highest score\n",
    "        argmax = max(sums, key=sums.get)\n",
    "        return argmax\n",
    "\n",
    "    def test_accuracy(self, data=None, data_type=None):\n",
    "        if data is None or data.empty:\n",
    "            raise ValueError(\"Cannot train on an empty corpus.\")\n",
    "            \n",
    "        correct_predictions = 0;\n",
    "        total_predictions = 0;\n",
    "    \n",
    "        for index, row in data.iterrows(): # used GPT to help me find how to iter on rows in my df\n",
    "            true_label = row['Y']\n",
    "            predicted_label = self.test_model(row[data_type])\n",
    "           # print(true_label, \"< true =?= predicted >\", predicted_label)\n",
    "    \n",
    "            total_predictions += 1\n",
    "            if predicted_label == true_label:\n",
    "                correct_predictions += 1\n",
    "    \n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        return round(accuracy * 100, 3)\n",
    "            \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        s += \"total docs    = \" + str(len(self.bigdoc)) + \"\\n\"\n",
    "        s += \"labels        = \" + str(self.classes)+ \"\\n\"\n",
    "        s += \"Voc        = \" + str(self.bigdoc_v)+ \"\\n\"\n",
    "        s+= \"_____________________\\n\"\n",
    "\n",
    "        for label in self.classes:\n",
    "            s += str(label) + \"\\n\"\n",
    "            s += \"Voc size    = \" + str(sum(self.bow[label][token] for token in self.bow[label])) + \"\\n\"\n",
    "            s += \"P(c)          = \" + str(self.logprior[label]) + \"\\n\"\n",
    "           # s += \"Logll         = \" + str(self.logll[label]) + \"\\n\"\n",
    "            s+= \"_____________________\\n\"\n",
    "        return s \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c369fb0a-7ef2-49d4-93cc-9381a0346af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegationNB(NaiveBayesClassifier):\n",
    "    def __init__(self, docs, classes, alpha = 0, voc = None):\n",
    "        \n",
    "        super().__init__(docs,classes, alpha = alpha, voc = voc)\n",
    "\n",
    "    def extract_features (self, docs):\n",
    "        \"\"\"creates unigram counts per class\n",
    "        \"\"\"\n",
    "        flattened_docs = [token \n",
    "                          for row in docs['Body_tokenized_Negation']\n",
    "                          for token in row if token in self.bigdoc_v]\n",
    "        \n",
    "        return Counter(flattened_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7dd16590-d281-4752-b305-62b6e9e751e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Body', 'Y', 'Body_tokenized', 'Body_tokenized_Negation'], dtype='object')\n",
      "(3500, 4)\n"
     ]
    }
   ],
   "source": [
    "# initialize test corpus and prepocess it\n",
    "test_corpus = pd.read_csv(\"data/test.csv\")\n",
    "# preprocess \n",
    "test_corpus['Body'] = test_corpus['Body'].apply(lambda x: remove_html_tags(x))\n",
    "test_corpus['Body_tokenized'] = test_corpus['Body'].apply(lambda x: WordPunctTokenizer().tokenize(x))\n",
    "test_corpus['Body_tokenized_Negation'] = test_corpus['Body_tokenized'].apply(lambda x: add_negation(x))\n",
    "\n",
    "print(test_corpus.keys())\n",
    "print(test_corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "40190ff7-38b4-44d3-878d-e44e77d2060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is consistent : True \n",
      "\n",
      "total docs    = 14000\n",
      "labels        = ['HQ', 'LQ']\n",
      "Voc        = <Vocabulary with cutoff=3 unk_label='<UNK>' and 37664 items>\n",
      "_____________________\n",
      "HQ\n",
      "Voc size    = 1340383\n",
      "P(c)          = -0.6931471805599453\n",
      "_____________________\n",
      "LQ\n",
      "Voc size    = 1221078\n",
      "P(c)          = -0.6931471805599453\n",
      "_____________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create binary class conditional model\n",
    "negativeMNB_Model = NegationNB(df_corpus, classes, alpha=1, voc = training_neg_voc) # smoothing according to optimal alpha\n",
    "negativeMNB_Model.train()\n",
    "print(negativeMNB_Model.check_consistency(), '\\n')\n",
    "\n",
    "print(negativeMNB_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "34c7a9f4-f4f2-4c75-b9b3-9fc111394438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy prediction for MNB with logical negation on test data :\n",
      " 83.114\n"
     ]
    }
   ],
   "source": [
    "negativeMNB_accuracy =  negativeMNB_Model.test_accuracy(test_corpus, data_type='Body_tokenized_Negation')\n",
    "print(\"Accuracy prediction for MNB with logical negation on test data :\\n\", negativeMNB_accuracy )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
